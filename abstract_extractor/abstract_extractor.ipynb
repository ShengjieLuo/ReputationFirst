{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from summa import summarizer\n",
    "from summa import keywords\n",
    "import nltk\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abstract_keywords(text):\n",
    "    return summarizer.summarize(text), keywords.keywords(text, split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2018-05-08 18:01:50.175473\n",
      "BRIEF-Adobe Systems Reports Qtrly Earnings Per Share of $1.55 On A Non-GAAP Basis\n",
      "1\n",
      "Wall Street advances on strong industrial data but posts weekly losses\n",
      "2\n",
      "Wall Street advances on strong industrial data but posts weekly losses\n",
      "3\n",
      "BUZZ-U.S. stocks weekly: Political pounding\n",
      "4\n",
      "US STOCKS-S&P advances on strong industrial output data\n",
      "5\n",
      "US STOCKS-Wall Street advances as financial, energy stocks gain\n",
      "6\n",
      "US STOCKS-Wall St higher as financial stocks gain on strong data\n",
      "7\n",
      "GLOBAL MARKETS-Stocks edge up, investors watchful as U.S. govt turmoil tests nerves\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "def get_result_list(file, num):\n",
    "    line_count = 0\n",
    "    abandon_count = 0\n",
    "    result_list = []\n",
    "    with open(file, 'r') as raw_data:\n",
    "        while line_count != num:\n",
    "            if line_count % 100 == 0:\n",
    "                print(line_count, datetime.datetime.now())\n",
    "            line_count += 1\n",
    "            json_data = json.loads(raw_data.readline())\n",
    "            abstract, keyword = get_abstract_keywords(json_data['text'])\n",
    "            name = json_data['company']\n",
    "            tags_words = list(map(lambda x: x[1:], json_data['tags']))\n",
    "            abstract_words = list(map(lambda x: x.lower(), nltk.tokenize.word_tokenize(abstract)))\n",
    "            title_words = list(map(lambda x: x.lower(), nltk.tokenize.word_tokenize(json_data['title'])))\n",
    "            if abstract != ''\\\n",
    "            and name not in abstract_words\\\n",
    "            and name not in title_words\\\n",
    "            and name not in tags_words:\n",
    "                abandon_count += 1\n",
    "                print(json_data['title'])\n",
    "                print(abandon_count)\n",
    "                continue\n",
    "            json_data['abstract'] = abstract\n",
    "            json_data['keywords'] = keyword\n",
    "            result_list.append(json.dumps(json_data))\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_demo(file, number_of_demo):\n",
    "    data = get_result_list(file, number_of_demo)\n",
    "    with open('data_output_sample.dat', 'w') as d:\n",
    "        for j in data:\n",
    "            d.write(j + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2018-05-08 19:10:06.721279\n",
      "error count: 1\n",
      "error count: 4\n",
      "error count: 5\n",
      "error count: 6\n",
      "error count: 7\n",
      "error count: 8\n",
      "error count: 9\n",
      "error count: 10\n",
      "10 2018-05-08 19:13:18.032483\n",
      "error count: 11\n",
      "error count: 12\n",
      "error count: 13\n",
      "error count: 14\n",
      "error count: 15\n",
      "error count: 16\n",
      "error count: 17\n",
      "error count: 18\n",
      "error count: 19\n",
      "error count: 20\n",
      "20 2018-05-08 19:15:05.189174\n",
      "error count: 21\n",
      "error count: 22\n",
      "error count: 23\n",
      "error count: 24\n",
      "error count: 25\n",
      "error count: 26\n",
      "error count: 27\n",
      "error count: 28\n",
      "error count: 29\n",
      "error count: 30\n",
      "30 2018-05-08 19:15:05.276137\n",
      "error count: 31\n",
      "error count: 32\n",
      "error count: 33\n",
      "error count: 34\n",
      "error count: 35\n",
      "error count: 36\n",
      "error count: 37\n",
      "error count: 38\n",
      "error count: 39\n",
      "error count: 40\n",
      "40 2018-05-08 19:15:05.347589\n",
      "error count: 41\n",
      "error count: 42\n",
      "error count: 43\n",
      "error count: 44\n",
      "error count: 45\n",
      "error count: 46\n",
      "error count: 47\n",
      "error count: 48\n",
      "error count: 49\n",
      "error count: 50\n",
      "50 2018-05-08 19:15:05.406508\n",
      "error count: 51\n",
      "error count: 52\n",
      "error count: 53\n",
      "error count: 54\n",
      "error count: 55\n",
      "error count: 56\n",
      "error count: 57\n",
      "error count: 58\n",
      "error count: 59\n",
      "error count: 60\n",
      "60 2018-05-08 19:15:05.464147\n",
      "error count: 61\n",
      "error count: 62\n",
      "error count: 63\n",
      "error count: 64\n",
      "error count: 65\n",
      "error count: 66\n",
      "error count: 67\n",
      "error count: 68\n",
      "error count: 69\n",
      "error count: 70\n",
      "70 2018-05-08 19:15:05.517638\n",
      "error count: 71\n",
      "error count: 72\n",
      "error count: 73\n",
      "error count: 74\n",
      "error count: 75\n",
      "error count: 76\n",
      "error count: 77\n",
      "error count: 78\n",
      "error count: 79\n",
      "error count: 80\n",
      "80 2018-05-08 19:15:05.589283\n",
      "error count: 81\n",
      "error count: 82\n",
      "error count: 83\n",
      "error count: 84\n",
      "error count: 85\n",
      "error count: 86\n",
      "error count: 87\n",
      "error count: 88\n",
      "error count: 89\n",
      "error count: 90\n",
      "90 2018-05-08 19:15:05.634997\n",
      "error count: 91\n",
      "error count: 92\n",
      "error count: 93\n",
      "error count: 94\n",
      "error count: 95\n",
      "error count: 96\n",
      "error count: 97\n",
      "error count: 98\n",
      "error count: 99\n",
      "error count: 100\n"
     ]
    }
   ],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "def get_coref_article(text, nlp):\n",
    "    return nlp.coref(text)\n",
    "\n",
    "def get_batch_coref(file, num):\n",
    "    result_list = []\n",
    "    line_count = 0\n",
    "    nlp = StanfordCoreNLP('http://localhost', port=9000)\n",
    "    with open(file, 'r') as raw_data:\n",
    "        while line_count != num:\n",
    "            if line_count % 10 == 0:\n",
    "                print(line_count, datetime.datetime.now())\n",
    "            line_count += 1\n",
    "            json_data = json.loads(raw_data.readline())\n",
    "            text = json_data['text']\n",
    "            try:\n",
    "                result_list.append(get_coref_article(text, nlp))\n",
    "                print(line_count)\n",
    "            except:\n",
    "                print('error count:', line_count)\n",
    "    nlp.close()\n",
    "    return result_list\n",
    "\n",
    "coref_data = get_batch_coref('688v2.dat', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
